{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "GHsq-CB-H4T5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "E3E1-m5dh4vb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =======================\n",
        "# HYPERPARAMETERS\n",
        "# =======================\n",
        "num_epochs = 4            # Jumlah epoch (berapa kali seluruh dataset dilatih)\n",
        "batch_size = 4            # Jumlah gambar per batch\n",
        "learning_rate = 0.001     # Learning rate optimizer\n",
        "\n",
        "# =======================\n",
        "# DATA TRANSFORM\n",
        "# =======================\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),                        # Mengubah gambar menjadi tensor (C, H, W)\n",
        "    transforms.Normalize(                         # Normalisasi pixel ke range [-1, 1]\n",
        "        (0.5, 0.5, 0.5),                          # Mean untuk 3 channel RGB\n",
        "        (0.5, 0.5, 0.5)                           # Std untuk 3 channel RGB\n",
        "    )\n",
        "])\n",
        "\n",
        "# =======================\n",
        "# DATASET CIFAR-10\n",
        "# =======================\n",
        "train_dataset = torchvision.datasets.CIFAR10(\n",
        "    root='./data',           # Folder penyimpanan dataset\n",
        "    train=True,              # Dataset training\n",
        "    download=True,           # Download jika belum ada\n",
        "    transform=transform      # Terapkan transform\n",
        ")\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(\n",
        "    root='./data',\n",
        "    train=False,             # Dataset testing\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "# =======================\n",
        "# DATALOADER\n",
        "# =======================\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,   # Ambil 4 gambar per batch\n",
        "    shuffle=True             # Acak data tiap epoch\n",
        ")\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False            # Tidak perlu diacak saat testing\n",
        ")\n",
        "\n",
        "# Label kelas CIFAR-10\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
        "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "# =======================\n",
        "# CNN MODEL\n",
        "# =======================\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvNet, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)      # Conv layer: input 3 channel RGB → 6 feature maps\n",
        "        self.pool = nn.MaxPool2d(2, 2)       # Max pooling 2x2 (downsampling)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)     # Conv layer kedua: 6 → 16 feature maps\n",
        "\n",
        "        self.fc1 = nn.Linear(16*5*5, 120)    # Fully connected layer\n",
        "        self.fc2 = nn.Linear(120, 84)        # Hidden FC layer\n",
        "        self.fc3 = nn.Linear(84, 10)         # Output layer (10 kelas CIFAR-10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x))) # Conv1 → ReLU → Pool\n",
        "        x = self.pool(F.relu(self.conv2(x))) # Conv2 → ReLU → Pool\n",
        "        x = x.view(-1, 16*5*5)               # Flatten tensor ke bentuk vektor\n",
        "        x = F.relu(self.fc1(x))              # Fully connected + ReLU\n",
        "        x = F.relu(self.fc2(x))              # Fully connected + ReLU\n",
        "        x = self.fc3(x)                      # Output logits (tanpa softmax)\n",
        "        return x\n",
        "\n",
        "# =======================\n",
        "# MODEL, LOSS, OPTIMIZER\n",
        "# =======================\n",
        "model = ConvNet().to(device)                # Kirim model ke CPU/GPU\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()           # Loss untuk klasifikasi multi-class\n",
        "optimizer = torch.optim.SGD(\n",
        "    model.parameters(),                     # Parameter yang akan diupdate\n",
        "    lr=learning_rate                        # Learning rate\n",
        ")\n",
        "\n",
        "# =======================\n",
        "# TRAINING LOOP\n",
        "# =======================\n",
        "n_total_steps = len(train_loader)            # Jumlah batch per epoch\n",
        "\n",
        "for epoch in range(num_epochs):              # Loop epoch\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "        images = images.to(device)           # Kirim gambar ke device\n",
        "        labels = labels.to(device)           # Kirim label ke device\n",
        "\n",
        "        outputs = model(images)              # Forward pass\n",
        "        loss = criterion(outputs, labels)    # Hitung loss\n",
        "\n",
        "        optimizer.zero_grad()                # Reset gradient\n",
        "        loss.backward()                      # Backpropagation\n",
        "        optimizer.step()                     # Update bobot\n",
        "\n",
        "        if (i+1) % 2000 == 0:                 # Print progress\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
        "                  f'Step [{i+1}/{n_total_steps}], '\n",
        "                  f'Loss: {loss.item():.4f}')\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "# =======================\n",
        "# EVALUATION\n",
        "# =======================\n",
        "with torch.no_grad():                        # Nonaktifkan gradient\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "\n",
        "    n_class_correct = [0 for _ in range(10)] # Benar per kelas\n",
        "    n_class_samples = [0 for _ in range(10)] # Total per kelas\n",
        "\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(images)              # Forward pass\n",
        "        _, predicted = torch.max(outputs, 1) # Ambil kelas dengan logit terbesar\n",
        "\n",
        "        n_samples += labels.size(0)\n",
        "        n_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        for i in range(batch_size):          # Hitung akurasi per kelas\n",
        "            label = labels[i]\n",
        "            pred = predicted[i]\n",
        "            if label == pred:\n",
        "                n_class_correct[label] += 1\n",
        "            n_class_samples[label] += 1\n",
        "\n",
        "    acc = 100.0 * n_correct / n_samples\n",
        "    print(f'Accuracy of the network: {acc} %')\n",
        "\n",
        "    for i in range(10):\n",
        "        acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
        "        print(f'Accuracy of {classes[i]}: {acc} %')\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# RINGKASAN:\n",
        "# Kode ini membangun dan melatih Convolutional Neural Network (CNN)\n",
        "# untuk klasifikasi gambar CIFAR-10 (10 kelas). Data diproses dalam\n",
        "# batch, dilewatkan ke layer convolution + pooling untuk ekstraksi\n",
        "# fitur, kemudian ke fully connected layer untuk klasifikasi.\n",
        "# Model dilatih menggunakan SGD dan CrossEntropyLoss, lalu diuji\n",
        "# untuk mendapatkan akurasi total dan akurasi per kelas.\n",
        "# ============================================================"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7HTsvK6h7qh",
        "outputId": "28c41d65-76a2-4928-c516-f1880e9e75dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/4], Step [2000/12500], Loss: 2.3360\n",
            "Epoch [1/4], Step [4000/12500], Loss: 2.3029\n",
            "Epoch [1/4], Step [6000/12500], Loss: 2.2754\n",
            "Epoch [1/4], Step [8000/12500], Loss: 2.2935\n",
            "Epoch [1/4], Step [10000/12500], Loss: 2.2955\n",
            "Epoch [1/4], Step [12000/12500], Loss: 2.2734\n",
            "Epoch [2/4], Step [2000/12500], Loss: 2.3114\n",
            "Epoch [2/4], Step [4000/12500], Loss: 2.2009\n",
            "Epoch [2/4], Step [6000/12500], Loss: 2.5225\n",
            "Epoch [2/4], Step [8000/12500], Loss: 2.3410\n",
            "Epoch [2/4], Step [10000/12500], Loss: 2.0884\n",
            "Epoch [2/4], Step [12000/12500], Loss: 2.0791\n",
            "Epoch [3/4], Step [2000/12500], Loss: 2.2530\n",
            "Epoch [3/4], Step [4000/12500], Loss: 1.6076\n",
            "Epoch [3/4], Step [6000/12500], Loss: 1.9960\n",
            "Epoch [3/4], Step [8000/12500], Loss: 1.8377\n",
            "Epoch [3/4], Step [10000/12500], Loss: 2.1582\n",
            "Epoch [3/4], Step [12000/12500], Loss: 0.9024\n",
            "Epoch [4/4], Step [2000/12500], Loss: 1.6744\n",
            "Epoch [4/4], Step [4000/12500], Loss: 1.1883\n",
            "Epoch [4/4], Step [6000/12500], Loss: 2.3448\n",
            "Epoch [4/4], Step [8000/12500], Loss: 1.2132\n",
            "Epoch [4/4], Step [10000/12500], Loss: 1.2881\n",
            "Epoch [4/4], Step [12000/12500], Loss: 1.0399\n",
            "Finished Training\n",
            "Accuracy of the network: 42.33 %\n",
            "Accuracy of plane: 43.2 %\n",
            "Accuracy of car: 73.8 %\n",
            "Accuracy of bird: 20.3 %\n",
            "Accuracy of cat: 15.8 %\n",
            "Accuracy of deer: 19.3 %\n",
            "Accuracy of dog: 51.8 %\n",
            "Accuracy of frog: 51.3 %\n",
            "Accuracy of horse: 50.7 %\n",
            "Accuracy of ship: 61.1 %\n",
            "Accuracy of truck: 36.0 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# CATATAN PENTING: CNN (Convolutional Neural Network)\n",
        "# ============================\n",
        "\n",
        "# 1. CNN adalah arsitektur neural network yang DIRANCANG KHUSUS\n",
        "#    untuk data spasial seperti gambar (image).\n",
        "#    CNN memanfaatkan struktur 2D (tinggi x lebar x channel).\n",
        "\n",
        "# 2. Alur umum CNN:\n",
        "#    Input Image\n",
        "#      → Convolutional Layer (ekstraksi fitur)\n",
        "#      → Activation (ReLU)\n",
        "#      → Pooling (downsampling)\n",
        "#      → (diulang beberapa kali)\n",
        "#      → Flatten\n",
        "#      → Fully Connected Layer\n",
        "#      → Output (klasifikasi)\n",
        "\n",
        "# 3. Convolutional Layer (nn.Conv2d):\n",
        "#    - Menerima input dalam bentuk (channels, height, width)\n",
        "#    - Parameter utama:\n",
        "#        in_channels  : jumlah channel input (RGB = 3, grayscale = 1)\n",
        "#        out_channels : jumlah filter / feature maps (bebas ditentukan)\n",
        "#        kernel_size  : ukuran filter (misal 3x3, 5x5)\n",
        "#    - out_channels menentukan JUMLAH FITUR yang dipelajari\n",
        "\n",
        "# 4. Output channel (jumlah filter) dan kernel size TIDAK FIX:\n",
        "#    - Dapat ditentukan bebas oleh perancang model\n",
        "#    - Dipilih berdasarkan:\n",
        "#        • kompleksitas data\n",
        "#        • kapasitas model\n",
        "#        • resource komputasi\n",
        "#    - Semakin banyak filter → semakin banyak fitur → lebih berat komputasi\n",
        "\n",
        "# 5. Activation Function (ReLU):\n",
        "#    - Diterapkan setelah convolutional layer\n",
        "#    - Menghilangkan nilai negatif\n",
        "#    - Memberikan non-linearitas\n",
        "#    - ReLU bekerja pada SETIAP neuron / pixel hasil convolution\n",
        "#    - Tanpa ReLU, CNN hanya menjadi kombinasi linear\n",
        "\n",
        "# 6. Pooling Layer (MaxPool2d):\n",
        "#    - Berfungsi untuk downsampling (mengurangi resolusi)\n",
        "#    - Contoh: kernel=2, stride=2 → ukuran menjadi setengah\n",
        "#    - Mengurangi komputasi dan meningkatkan robustness\n",
        "#    - Pooling BUKAN layer pembelajaran (tidak punya parameter)\n",
        "\n",
        "# 7. Mengapa Convolution dilakukan SEBELUM Fully Connected?\n",
        "#    - Conv layer → mengekstraksi fitur lokal & hierarkis\n",
        "#    - FC layer → mengambil keputusan berdasarkan fitur global\n",
        "#    - CNN memisahkan:\n",
        "#        • feature extraction (Conv)\n",
        "#        • classification (FC)\n",
        "\n",
        "# 8. Flatten:\n",
        "#    - Mengubah feature map (C x H x W) menjadi vektor 1D\n",
        "#    - Wajib sebelum masuk Fully Connected Layer\n",
        "\n",
        "# 9. Fully Connected Layer (nn.Linear):\n",
        "#    - Menggabungkan semua fitur hasil convolution\n",
        "#    - Bertindak sebagai classifier\n",
        "#    - Biasanya tetap menggunakan ReLU (kecuali layer output)\n",
        "\n",
        "# 10. Output Layer:\n",
        "#     - Tidak menggunakan ReLU\n",
        "#     - Menghasilkan logits (skor kelas)\n",
        "#     - Logits akan diproses oleh:\n",
        "#         • Softmax (multi-class)\n",
        "#         • Sigmoid (binary classification)\n",
        "\n",
        "# 11. CNN unggul karena:\n",
        "#     - Mempertahankan struktur spasial gambar\n",
        "#     - Menggunakan weight sharing\n",
        "#     - Parameter lebih efisien dibanding MLP\n",
        "#     - Lebih akurat dan stabil untuk image classification\n",
        "\n",
        "# ============================\n",
        "# RINGKASAN:\n",
        "# CNN memisahkan proses ekstraksi fitur (Conv + ReLU + Pool)\n",
        "# dan pengambilan keputusan (Fully Connected),\n",
        "# sehingga sangat efektif untuk klasifikasi gambar.\n",
        "# ============================\n"
      ],
      "metadata": {
        "id": "-NnxWSlhg9nV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}