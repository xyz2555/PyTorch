{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "UpCOKFExLlKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self, n_input_features):\n",
        "    super(Model, self).__init__()\n",
        "    # Memanggil constructor dari nn.Module\n",
        "\n",
        "    self.linear = nn.Linear(n_input_features, 1)\n",
        "    # Layer linear (fully connected)\n",
        "    # - Input  : n_input_features (misalnya 6 fitur)\n",
        "    # - Output : 1 neuron\n",
        "    # Cocok untuk binary classification atau regresi\n",
        "\n",
        "  def forward(self, x):\n",
        "    # Fungsi forward: mendefinisikan alur data di model\n",
        "\n",
        "    y_pred = torch.sigmoid(self.linear(x))\n",
        "    # 1) x masuk ke linear layer → menghasilkan logits\n",
        "    # 2) sigmoid mengubah logits menjadi nilai antara 0–1 (probabilitas)\n",
        "\n",
        "    return y_pred\n",
        "    # Mengembalikan prediksi akhir\n",
        "\n",
        "model = Model(n_input_features = 6)\n",
        "# Membuat instance model dengan 6 fitur input\n",
        "\n",
        "# for param in model.parameters():\n",
        "#   print(param)\n",
        "# (Opsional) Menampilkan semua parameter model (weight & bias)\n",
        "\n",
        "# FILE = '/content/model.pth'\n",
        "# # torch.save(model, FILE)\n",
        "# torch.save(model.state_dict(), FILE)\n",
        "# Menyimpan parameter model saja (state_dict)\n",
        "# Cara ini lebih fleksibel dan direkomendasikan\n",
        "\n",
        "# # model = torch.load(FILE, weights_only=False)\n",
        "# # model.eval()\n",
        "# Contoh load model secara langsung (kurang direkomendasikan)\n",
        "\n",
        "# loaded_model = Model(n_input_features=6)\n",
        "# loaded_model.load_state_dict(torch.load(FILE))\n",
        "# loaded_model.eval()\n",
        "# Cara yang direkomendasikan:\n",
        "# 1) Buat instance model\n",
        "# 2) Load state_dict\n",
        "# 3) Set ke mode evaluasi\n",
        "\n",
        "# for param in model.parameters():\n",
        "#   print(param)\n",
        "# (Opsional) Cek ulang parameter setelah load\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ly9i2Q9ULntn",
        "outputId": "ae2fe614-3177-41a1-df26-cc15762be354"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.3750,  0.1141,  0.3260, -0.3970,  0.2900, -0.2225]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.1485], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.3750,  0.1141,  0.3260, -0.3970,  0.2900, -0.2225]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.1485], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.01\n",
        "# Learning rate optimizer\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
        "# Membuat optimizer SGD\n",
        "# - Mengoptimasi parameter model\n",
        "# - Learning rate = 0.01\n",
        "\n",
        "print(optimizer.state_dict())\n",
        "# Menampilkan state optimizer:\n",
        "# - parameter groups\n",
        "# - momentum (jika ada)\n",
        "# - learning rate, dll\n",
        "\n",
        "# checkpoint = {\n",
        "#     'epoch': 90,\n",
        "#     'model_state': model.state_dict(),\n",
        "#     'optim_state': optimizer.state_dict()\n",
        "# }\n",
        "# Membuat checkpoint:\n",
        "# - epoch terakhir\n",
        "# - state model\n",
        "# - state optimizer\n",
        "\n",
        "# torch.save(checkpoint, 'checkpoint.pth')\n",
        "# Menyimpan checkpoint ke file\n",
        "\n",
        "loaded_checkpoint = torch.load('checkpoint.pth')\n",
        "# Memuat checkpoint dari file\n",
        "\n",
        "epoch = loaded_checkpoint['epoch']\n",
        "# Mengambil informasi epoch terakhir training\n",
        "\n",
        "model = Model(n_input_features=6)\n",
        "# Membuat ulang model (arsitektur HARUS sama)\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0)\n",
        "# Membuat optimizer baru\n",
        "# Learning rate akan ditimpa oleh state_dict optimizer\n",
        "\n",
        "model.load_state_dict(loaded_checkpoint['model_state'])\n",
        "# Memuat parameter model dari checkpoint\n",
        "\n",
        "optimizer.load_state_dict(loaded_checkpoint['optim_state'])\n",
        "# Memuat state optimizer dari checkpoint\n",
        "# (termasuk learning rate, momentum, dll)\n",
        "\n",
        "print(optimizer.state_dict())\n",
        "# Menampilkan state optimizer setelah load\n",
        "# Menunjukkan bahwa optimizer berhasil direstore"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3AFStvFmMouH",
        "outputId": "307b0618-4477-49a3-9cca-eae6271f4865"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'state': {}, 'param_groups': [{'lr': 0.01, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False, 'fused': None, 'params': [0, 1]}]}\n",
            "{'state': {}, 'param_groups': [{'lr': 0.01, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False, 'fused': None, 'params': [0, 1]}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Checkpoint\n",
        "#    - Checkpoint menyimpan:\n",
        "#      a) epoch terakhir\n",
        "#      b) parameter model\n",
        "#      c) state optimizer\n",
        "#    - Berguna untuk melanjutkan training dari titik terakhir\n",
        "#\n",
        "# 5. Loading Checkpoint\n",
        "#    - Arsitektur model harus sama\n",
        "#    - state_dict model dan optimizer di-restore\n",
        "#    - Training bisa dilanjutkan tanpa kehilangan informasi\n",
        "#\n",
        "# Intinya:\n",
        "# Code ini menunjukkan cara menyimpan dan memuat\n",
        "# model + optimizer + epoch untuk training berkelanjutan."
      ],
      "metadata": {
        "id": "mRVueYhvR44Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}