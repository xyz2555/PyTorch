{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "VQelaAC96_ZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNet(nn.Module):\n",
        "  # Mendefinisikan class NeuralNet yang mewarisi nn.Module (kelas dasar semua model PyTorch)\n",
        "  def __init__ (self, input_size, hidden_size):\n",
        "    super(NeuralNet, self).__init__()\n",
        "    # Memanggil constructor dari nn.Module agar mekanisme internal PyTorch aktif\n",
        "\n",
        "    self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "    # Layer linear pertama: mengubah input (input_size) ke hidden layer (hidden_size)\n",
        "\n",
        "    self.relu = nn.ReLU()\n",
        "    # Fungsi aktivasi ReLU (Rectified Linear Unit)\n",
        "\n",
        "    self.linear2 = nn.Linear(hidden_size, 1)\n",
        "    # Layer linear kedua: mengubah hidden layer menjadi 1 output (biasanya untuk binary classification)\n",
        "\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    # Fungsi aktivasi sigmoid untuk menghasilkan output probabilitas (0–1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # Fungsi forward yang otomatis dipanggil saat model(x) dijalankan\n",
        "    out = self.linear1(x)\n",
        "    # Operasi linear pertama: xW + b\n",
        "\n",
        "    out = self.relu(x)\n",
        "    # Aktivasi ReLU (CATATAN: secara logika seharusnya relu(out), bukan relu(x))\n",
        "\n",
        "    out = self.linear2(x)\n",
        "    # Operasi linear kedua (CATATAN: seharusnya menggunakan output sebelumnya)\n",
        "\n",
        "    out = self.sigmoid(x)\n",
        "    # Aktivasi sigmoid (CATATAN: kembali menggunakan x, bukan out)\n",
        "\n",
        "    return out\n",
        "    # Mengembalikan hasil akhir model"
      ],
      "metadata": {
        "id": "2NVKUD7VDm8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNet(nn.Module):\n",
        "  # Class NeuralNet didefinisikan ULANG → definisi ini akan MENIMPA class NeuralNet sebelumnya\n",
        "  def __init__ (self, input_size, hidden_size):\n",
        "    super(NeuralNet, self).__init__()\n",
        "    # Memanggil constructor parent class\n",
        "\n",
        "    self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "    # Layer pertama: input ke hidden layer\n",
        "\n",
        "    self.linear2 = nn.Linear(hidden_size, 1)\n",
        "    # Layer kedua: input_size ke hidden_size (CATATAN: biasanya hidden_size ke output_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # Forward pass model\n",
        "    out = torch.relu(self.linear1(x))\n",
        "    # Input x masuk ke linear1 lalu diaktifkan dengan ReLU\n",
        "\n",
        "    out = torch.sigmoid(self.linear2(out))\n",
        "    # Output dari layer pertama masuk ke layer kedua lalu sigmoid\n",
        "\n",
        "    return out\n",
        "    # Mengembalikan output akhir jaringan\n",
        "\n",
        "\n",
        "# RINGKASAN:\n",
        "# Kode ini mendefinisikan neural network sederhana menggunakan PyTorch.\n",
        "# Class NeuralNet didefinisikan dua kali, dan definisi kedua akan menimpa yang pertama.\n",
        "# Model menggunakan kombinasi layer linear dan fungsi aktivasi (ReLU dan Sigmoid).\n",
        "# Fungsi forward menentukan alur data saat model dipanggil dengan input.\n",
        "# Output sigmoid biasanya digunakan untuk binary classification."
      ],
      "metadata": {
        "id": "R6ZPoMCAEFLh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}